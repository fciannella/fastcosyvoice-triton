#!/usr/bin/env python3
"""
–¢–µ—Å—Ç TRT-LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–ª—è CosyVoice3.

–≠—Ç–æ—Ç —Å–∫—Ä–∏–ø—Ç:
1. –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç CosyVoice3 –≤ merged HuggingFace –º–æ–¥–µ–ª—å
2. –°–æ–±–∏—Ä–∞–µ—Ç TRT-LLM engine
3. –°–∏–Ω—Ç–µ–∑–∏—Ä—É–µ—Ç —Ç–µ—Å—Ç–æ–≤—É—é —Ä–µ—á—å
4. –°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –ø—Ä–æ—Å–ª—É—à–∏–≤–∞–Ω–∏—è

Usage:
    python test_trt.py
"""
import os
import sys
import time
import logging

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç–∏
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))
sys.path.insert(0, os.path.join(os.path.dirname(os.path.abspath(__file__)), 'third_party/Matcha-TTS'))

import torch
import torchaudio

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)

# ============================================================================
# –ö–û–ù–§–ò–ì–£–†–ê–¶–ò–Ø
# ============================================================================

MODEL_DIR = 'pretrained_models/Fun-CosyVoice3-0.5B'
REFERENCE_AUDIO = 'refs/audio5.wav'
OUTPUT_DIR = 'output_trt_test'
DTYPE = 'bfloat16'

# –¢–µ–∫—Å—Ç—ã –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞
TEST_TEXTS = [
    "–ü—Ä–∏–≤–µ—Ç! –≠—Ç–æ —Ç–µ—Å—Ç TensorRT-LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –¥–ª—è CosyVoice3.",
    "–ï—Å–ª–∏ –≤—ã —Å–ª—ã—à–∏—Ç–µ —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç, –∑–Ω–∞—á–∏—Ç –≤—Å—ë —Ä–∞–±–æ—Ç–∞–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ!",
    "–¢–µ–ø–µ—Ä—å –º–æ–¥–µ–ª—å –∏—Å–ø–æ–ª—å–∑—É–µ—Ç –ø–æ–ª–Ω–æ–µ TRT-LLM —É—Å–∫–æ—Ä–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∏–ª—å–Ω–æ–π –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π.",
]

INSTRUCTION = "You are a helpful assistant."


def get_gpu_memory():
    """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ GPU –ø–∞–º—è—Ç–∏."""
    if not torch.cuda.is_available():
        return 0.0, 0.0
    allocated = torch.cuda.memory_allocated() / (1024 ** 3)
    reserved = torch.cuda.memory_reserved() / (1024 ** 3)
    return allocated, reserved


def load_prompt_text(audio_path: str) -> str:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—é –∏–∑ txt —Ñ–∞–π–ª–∞."""
    txt_path = audio_path.rsplit('.', 1)[0] + '.txt'
    with open(txt_path, 'r', encoding='utf-8') as f:
        transcription = f.read().strip()
    return f"{INSTRUCTION}<|endofprompt|>{transcription}"


def test_trt_llm():
    """–û—Å–Ω–æ–≤–Ω–æ–π —Ç–µ—Å—Ç TRT-LLM –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏."""
    print("=" * 70)
    print("üöÄ CosyVoice3 TRT-LLM Integration Test")
    print("=" * 70)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–∞–π–ª—ã
    if not os.path.exists(MODEL_DIR):
        logger.error(f"Model not found: {MODEL_DIR}")
        return False
    
    if not os.path.exists(REFERENCE_AUDIO):
        logger.error(f"Reference audio not found: {REFERENCE_AUDIO}")
        return False
    
    os.makedirs(OUTPUT_DIR, exist_ok=True)
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º prompt
    prompt_text = load_prompt_text(REFERENCE_AUDIO)
    print(f"\nüìù Reference: {REFERENCE_AUDIO}")
    
    # =========================================================================
    # –®–∞–≥ 1: –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ —Å TRT-LLM
    # =========================================================================
    print("\n" + "=" * 70)
    print("üì¶ Step 1: Loading FastCosyVoice3 with TRT-LLM")
    print("=" * 70)
    
    alloc, res = get_gpu_memory()
    print(f"GPU Memory [before]: {alloc:.2f} GB allocated, {res:.2f} GB reserved")
    
    load_start = time.time()
    
    from fastcosyvoice import FastCosyVoice3
    
    cosyvoice = FastCosyVoice3(
        model_dir=MODEL_DIR,
        fp16=True,
        load_vllm=False,
        load_trt=True,           # TensorRT for Flow
        load_trt_llm=True,       # TensorRT-LLM for LLM
        trt_llm_dtype=DTYPE,
    )
    
    load_time = time.time() - load_start
    print(f"‚úÖ Model loaded in {load_time:.2f}s")
    
    alloc, res = get_gpu_memory()
    print(f"GPU Memory [after load]: {alloc:.2f} GB allocated, {res:.2f} GB reserved")
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å TRT-LLM
    if cosyvoice.trt_llm_loaded:
        print("‚úÖ TRT-LLM: LOADED")
        print(f"   Speech token offset: {cosyvoice.speech_token_offset}")
        print(f"   Speech token size: {cosyvoice.speech_token_size}")
    else:
        print("‚ùå TRT-LLM: NOT LOADED (using PyTorch)")
        logger.warning("TRT-LLM not loaded! Check logs above for errors.")
    
    # =========================================================================
    # –®–∞–≥ 2: –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Å–ø–∏–∫–µ—Ä–∞
    # =========================================================================
    print("\n" + "=" * 70)
    print("üé§ Step 2: Preparing speaker embeddings")
    print("=" * 70)
    
    spk_id = "test_speaker"
    embed_start = time.time()
    cosyvoice.add_zero_shot_spk(prompt_text, REFERENCE_AUDIO, spk_id)
    embed_time = time.time() - embed_start
    print(f"‚úÖ Speaker embeddings prepared in {embed_time:.3f}s")
    
    # =========================================================================
    # –®–∞–≥ 3: –ü—Ä–æ–≥—Ä–µ–≤
    # =========================================================================
    print("\n" + "=" * 70)
    print("üî• Step 3: Warmup")
    print("=" * 70)
    
    warmup_start = time.time()
    # Use a longer warmup text to better match real usage
    warmup_text = "–≠—Ç–æ —Ç–µ—Å—Ç –ø—Ä–æ–≥—Ä–µ–≤–∞ –º–æ–¥–µ–ª–∏ –¥–ª—è —Å–∏–Ω—Ç–µ–∑–∞ —Ä–µ—á–∏."
    
    for chunk in cosyvoice.inference_zero_shot_stream(
        tts_text=warmup_text,
        prompt_text=prompt_text,
        prompt_wav=REFERENCE_AUDIO,
        zero_shot_spk_id=spk_id,
    ):
        pass  # –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≥—Ä–µ–≤–∞–µ–º
    
    if torch.cuda.is_available():
        torch.cuda.synchronize()
        # Clear VRAM after warmup
        torch.cuda.empty_cache()
    
    warmup_time = time.time() - warmup_start
    alloc, res = get_gpu_memory()
    print(f"‚úÖ Warmup complete in {warmup_time:.2f}s")
    print(f"GPU Memory [after warmup+cleanup]: {alloc:.2f} GB allocated, {res:.2f} GB reserved")
    
    # =========================================================================
    # –®–∞–≥ 4: –°–∏–Ω—Ç–µ–∑ —Ç–µ—Å—Ç–æ–≤—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
    # =========================================================================
    print("\n" + "=" * 70)
    print("üéµ Step 4: Synthesizing test audio")
    print("=" * 70)
    
    all_results = []
    
    for idx, text in enumerate(TEST_TEXTS, 1):
        print(f"\n--- Text {idx}/{len(TEST_TEXTS)} ---")
        print(f"üìù {text[:60]}{'...' if len(text) > 60 else ''}")
        
        audio_chunks = []
        chunk_count = 0
        
        synth_start = time.time()
        first_chunk_time = None
        
        for chunk in cosyvoice.inference_zero_shot_stream(
            tts_text=text,
            prompt_text=prompt_text,
            prompt_wav=REFERENCE_AUDIO,
            zero_shot_spk_id=spk_id,
        ):
            chunk_count += 1
            if first_chunk_time is None:
                if torch.cuda.is_available():
                    torch.cuda.synchronize()
                first_chunk_time = time.time() - synth_start
            
            audio_chunks.append(chunk['tts_speech'])
        
        if torch.cuda.is_available():
            torch.cuda.synchronize()
        
        total_time = time.time() - synth_start
        
        if audio_chunks:
            full_audio = torch.cat(audio_chunks, dim=1)
            audio_duration = full_audio.shape[1] / cosyvoice.sample_rate
            rtf = total_time / audio_duration if audio_duration > 0 else float('inf')
            
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º
            output_path = os.path.join(OUTPUT_DIR, f'trt_test_{idx:02d}.wav')
            torchaudio.save(output_path, full_audio, cosyvoice.sample_rate)
            
            print(f"üíæ Saved: {output_path}")
            print(f"   TTFB: {first_chunk_time:.3f}s")
            print(f"   Duration: {audio_duration:.2f}s")
            print(f"   Total time: {total_time:.3f}s")
            print(f"   RTF: {rtf:.3f}")
            print(f"   Chunks: {chunk_count}")
            
            if rtf < 1.0:
                print(f"   ‚úÖ {1/rtf:.1f}x faster than realtime")
            else:
                print(f"   ‚ö†Ô∏è {rtf:.1f}x slower than realtime")
            
            all_results.append({
                'text': text,
                'ttfb': first_chunk_time,
                'duration': audio_duration,
                'total_time': total_time,
                'rtf': rtf,
                'chunks': chunk_count,
                'output': output_path,
            })
        else:
            print("   ‚ùå No audio generated!")
            all_results.append({
                'text': text,
                'error': 'No audio generated',
            })
    
    # =========================================================================
    # –ò—Ç–æ–≥–∏
    # =========================================================================
    print("\n" + "=" * 70)
    print("üìä SUMMARY")
    print("=" * 70)
    
    successful = [r for r in all_results if 'error' not in r]
    
    if successful:
        avg_ttfb = sum(r['ttfb'] for r in successful) / len(successful)
        avg_rtf = sum(r['rtf'] for r in successful) / len(successful)
        total_duration = sum(r['duration'] for r in successful)
        total_time = sum(r['total_time'] for r in successful)
        
        print(f"TRT-LLM Status: {'‚úÖ ENABLED' if cosyvoice.trt_llm_loaded else '‚ùå DISABLED'}")
        print(f"Tests passed: {len(successful)}/{len(all_results)}")
        print(f"Average TTFB: {avg_ttfb:.3f}s")
        print(f"Average RTF: {avg_rtf:.3f}")
        print(f"Total audio: {total_duration:.2f}s")
        print(f"Total time: {total_time:.2f}s")
        
        if avg_rtf < 1.0:
            print(f"\n‚úÖ Overall: {1/avg_rtf:.1f}x faster than realtime!")
        
        print(f"\nüìÅ Output files saved to: {OUTPUT_DIR}/")
        print("\nGenerated files:")
        for r in successful:
            print(f"  - {r['output']}")
        
        return True
    else:
        print("‚ùå All tests failed!")
        return False


def main():
    try:
        success = test_trt_llm()
        
        print("\n" + "=" * 70)
        if success:
            print("‚úÖ TEST PASSED!")
            print("=" * 70)
            print("\nüéß –ü–æ—Å–ª—É—à–∞–π –∞—É–¥–∏–æ —Ñ–∞–π–ª—ã –≤ –ø–∞–ø–∫–µ output_trt_test/")
        else:
            print("‚ùå TEST FAILED!")
            print("=" * 70)
        
    except Exception as e:
        logger.error(f"Test failed with error: {e}", exc_info=True)
        print("\n" + "=" * 70)
        print("‚ùå TEST FAILED WITH EXCEPTION!")
        print("=" * 70)
        raise


if __name__ == '__main__':
    main()

